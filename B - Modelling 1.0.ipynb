{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\gebruiker\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# For data processing\n",
    "import pandas as pd\n",
    "\n",
    "# Matrix math\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# For unnesting nested list/array\n",
    "from itertools import chain\n",
    "\n",
    "# Keras for deep learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Scikit learn for mapping metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#for logging\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Attempt to utilize GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from numba import cuda\n",
    "from numba import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17642965675985899821\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6679640146\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16427432008248608331\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Feat_Eng_B.csv\", sep=\"\\t\", encoding='utf-8')\n",
    "df.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "# Drop Acorn as this can already be inferred\n",
    "df.drop('Acorn', axis = 1, inplace=True)\n",
    "# Remove dummy trap colums\n",
    "trap_dummies = ['isNight', 'isWinter']\n",
    "df.drop(trap_dummies, axis = 1, inplace = True)\n",
    "# Drop variables due to missing data\n",
    "df.drop('cloudCover',axis=1,inplace=True)\n",
    "df.drop('dewPoint',axis=1,inplace=True)\n",
    "df.drop('apparentTemperature',axis=1,inplace=True)\n",
    "df.drop('visibility',axis=1,inplace=True)\n",
    "df.drop('windSpeed',axis=1,inplace=True)\n",
    "df.drop('windBearing',axis=1,inplace=True)\n",
    "# Drop variables deemed irrelevant by statistical analysis\n",
    "df.drop('pressure', axis=1, inplace=True)\n",
    "# Sort values by smart meter\n",
    "df = df[(df['Year'] < 2014) | ((df['Year'] == 2014) & (df['Month'] == 1) & (df['Day'] == 1) & (df['Hour'] < 12.5))]\n",
    "df['LCLid'] = df['LCLid'].apply(str)\n",
    "df = df[df['LCLid'] != '0']\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(merged_df):\n",
    "    vals = merged_df.values\n",
    "    # Save relevant columns to list\n",
    "    ## Save ID by period\n",
    "    ID = [vals[i,0] for i in range(len(vals))]\n",
    "    ## Normalize quantitative variables\n",
    "    humidity = [(vals[i,6] / vals[i,18])-1 for i in range(len(vals))]\n",
    "    temperature = [(vals[i,7] / vals[i,19])-1 for i in range(len(vals))]\n",
    "    KWH = [(vals[i,16]) for i in range(len(vals))]\n",
    "    ## Save Binaries\n",
    "    StdorToU = [vals[i,8] for i in range(len(vals))]\n",
    "    isAutumn = [vals[i,9] for i in range(len(vals))]\n",
    "    isSpring = [vals[i,10] for i in range(len(vals))]\n",
    "    isSummer = [vals[i,11] for i in range(len(vals))]\n",
    "    isHoliday = [vals[i,12] for i in range(len(vals))]\n",
    "    isPeak = [vals[i,13] for i in range(len(vals))]\n",
    "    isOff_Peak = [vals[i,14] for i in range(len(vals))]\n",
    "    isWeekend = [vals[i,15] for i in range(len(vals))]\n",
    "    # Save normalization factors to list\n",
    "    y_Normalization_Factors = [vals[i,20] for i in range(len(vals))]\n",
    "    cols = ['LCLid','humidity','Temperature', 'StdorToU', 'isAutumn', 'isSpring', 'isSummer', 'isHoliday', \n",
    "            'isPeak', 'isOff_Peak', 'isWeekend', 'KWH_hh']\n",
    "    new_df = pd.DataFrame(np.column_stack([ID, humidity, temperature, StdorToU, isAutumn, isSpring, \n",
    "                                           isSummer, isHoliday, isPeak, isOff_Peak, isWeekend,\n",
    "                                           KWH]), columns=cols).values\n",
    "    factors = y_Normalization_Factors\n",
    "    return new_df, factors #, ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(sm):\n",
    "    # Create period columns from MACID, Year, Month, Day, Evening,Morning,Night Dummies\n",
    "    sm[\"period\"] = (sm.loc[:,\"LCLid\"].map(str) + sm.loc[:,\"Year\"].map(str) + sm.loc[:,\"Month\"].map(str) + sm.loc[:,\"Day\"].map(str) + sm.loc[:,\"isPeak\"].map(str) + sm.loc[:,\"isOff_Peak\"].map(str))\n",
    "    # create aggregated object by 'period' \n",
    "    sm_ID_agg = sm.groupby('period')\n",
    "    # Extract mean from aggregated list\n",
    "    sm_aggregated_mean = sm_ID_agg.aggregate(np.mean)\n",
    "    list_ = ['Year', 'Month', 'Day', 'Hour', 'StdorToU', 'isAutumn',\n",
    "           'isSpring', 'isSummer', 'isHoliday', 'isPeak', 'isOff_Peak',\n",
    "           'isWeekend']\n",
    "    sm_aggregated_mean.drop(list_, axis = 1, inplace = True)\n",
    "    # Merge sm with mean values on period IDs\n",
    "    normalization_df = pd.merge(sm, sm_aggregated_mean, how=\"outer\", on=\"period\")\n",
    "    # Normalize df, return normalizeD df and normalization factors\n",
    "    raw_data, normalization_factors = normalize_df(normalization_df)\n",
    "    return raw_data, list(sm[\"DateTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data(raw_data, timestamps, days):\n",
    "    # Amount of data that is used for training prediction\n",
    "    sequence_length = days*48\n",
    "    # Number of ending, up to, index for testing\n",
    "    window_length = sequence_length+48\n",
    "    #Convert the file to a list\n",
    "    data = np.array(raw_data.tolist())  \n",
    "    X_train = data[0:sequence_length, 0:len(data[0])-1]\n",
    "    y_train = data[0:sequence_length, len(data[0])-1]\n",
    "    X_test = data[sequence_length:window_length, 0:len(data[0])-1]\n",
    "    y_test = data[sequence_length:window_length,len(data[0])-1]\n",
    "    timestamps_test = timestamps[sequence_length:window_length]\n",
    "    return X_train, y_train, X_test, y_test, timestamps_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(X_train, loss_function, optimizer):\n",
    "    #Create a Sequential model using Keras\n",
    "    model = Sequential()\n",
    "    #First MLP layer\n",
    "    model.add(Dense(11,input_shape=(X_train.shape[1],)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.3))\n",
    "    #Second MLP layer\n",
    "    model.add(Dense(11))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #Output layer (returns the predicted value)\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    #Set loss function and optimizer\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, Y_train, batch_num, num_epoch, val_split):\n",
    "    #Train the model on X_train and Y_train\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        model.fit(X_train, Y_train, batch_size= batch_num, epochs=num_epoch, validation_split= val_split, verbose = 0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test):\n",
    "    #Test the model on X_Test\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        y_predict = model.predict(X_test)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_365(df, meter, train_days, test_days):\n",
    "    sm = df[df.LCLid == meter]\n",
    "    sm, timestamps = feature_scaling(sm)\n",
    "    sm = sm[:,1:]\n",
    "    # Initialize predictions list\n",
    "    predictions = []\n",
    "    #Record the time the model starts training\n",
    "    start = time.time()\n",
    "    # Initialize iteration value\n",
    "    i = 0\n",
    "    while i < test_days:\n",
    "        X_train, y_train, X_test, y_test, timestamps_test = model_data(sm, timestamps, train_days)\n",
    "        model = initialize_model(X_train, loss_function='mean_squared_error', optimizer='adam')\n",
    "        model = fit_model(model, X_train, y_train, batch_num = 256, num_epoch = 35, val_split = .3)\n",
    "        y_predict = test_model(model, X_test)\n",
    "        for x in range(len(y_predict)):\n",
    "            predictions.append([y_predict[x][0], y_test[x], timestamps_test[x], meter])\n",
    "        sm = sm[48:,:]\n",
    "        timestamps = timestamps[48:]\n",
    "        if i % 30 == 0:\n",
    "            print('Epoch: ',i)\n",
    "        i += 1\n",
    "    proc_time = int(math.floor(time.time() - start))\n",
    "    print('Predictions for ',meter,' takes ', proc_time, ' seconds, for ', i, ' days.')\n",
    "    ## Merge Data\n",
    "    predictions = np.array(predictions)\n",
    "    pred_all = pd.DataFrame({'LCLid': predictions[:,3], 'DateTime': predictions[:,2], 'y_test': predictions[:,1], \n",
    "                             'y_hat':predictions[:,0]})  \n",
    "    pred_all.to_csv((meter+\".csv\"), sep=\"\\t\", encoding='utf-8')\n",
    "    return pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(y_predict, Y_test):\n",
    "    #Get Mean Squared Error\n",
    "    RMSE = math.sqrt(mean_squared_error(y_predict.flatten(), Y_test.flatten()))\n",
    "    # Get Mean Absolute Error\n",
    "    MAE = mean_absolute_error(y_predict.flatten(), Y_test.flatten())\n",
    "    # Get Pearson product-moment correlation coefficients\n",
    "    corr = np.corrcoef(y_predict, Y_test)[1][0]**2\n",
    "    return RMSE, MAE, corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>StdorToU</th>\n",
       "      <th>isAutumn</th>\n",
       "      <th>isSpring</th>\n",
       "      <th>isSummer</th>\n",
       "      <th>isHoliday</th>\n",
       "      <th>isPeak</th>\n",
       "      <th>isOff_Peak</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>KWH_hh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC001966</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-11-01 00:00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.193333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC003355</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-11-01 00:00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.193333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC003445</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-11-01 00:00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.193333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC003876</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-11-01 00:00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.193333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC004567</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-11-01 00:00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.193333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid  Year  Month  Day  Hour          DateTime  humidity  temperature  \\\n",
       "0  MAC001966  2012     11    1   0.0  2012-11-01 00:00      0.82    11.193333   \n",
       "1  MAC003355  2012     11    1   0.0  2012-11-01 00:00      0.82    11.193333   \n",
       "2  MAC003445  2012     11    1   0.0  2012-11-01 00:00      0.82    11.193333   \n",
       "3  MAC003876  2012     11    1   0.0  2012-11-01 00:00      0.82    11.193333   \n",
       "4  MAC004567  2012     11    1   0.0  2012-11-01 00:00      0.82    11.193333   \n",
       "\n",
       "   StdorToU  isAutumn  isSpring  isSummer  isHoliday  isPeak  isOff_Peak  \\\n",
       "0         1         1         0         0          0       0           0   \n",
       "1         1         1         0         0          0       0           0   \n",
       "2         1         1         0         0          0       0           0   \n",
       "3         1         1         0         0          0       0           0   \n",
       "4         1         1         0         0          0       0           0   \n",
       "\n",
       "   isWeekend  KWH_hh  \n",
       "0          0   0.162  \n",
       "1          0   0.248  \n",
       "2          0   0.507  \n",
       "3          0   0.139  \n",
       "4          0   0.054  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_meters = list(set(df.values[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping throughout the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at iteration 0 for smart meter: MAC003876, last iteration is at iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gebruiker\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  30\n",
      "Epoch:  60\n",
      "Epoch:  90\n",
      "Epoch:  120\n",
      "Epoch:  150\n",
      "Epoch:  180\n",
      "Epoch:  210\n",
      "Epoch:  240\n"
     ]
    }
   ],
   "source": [
    "ep = 0\n",
    "print(\"We're at iteration \" + str(ep) + ' for smart meter: ' + smart_meters[ep] + \", last iteration is at iteration \" + str(len(smart_meters)-1))\n",
    "rand_sm_pred = predict_365(df, smart_meters[ep], train_days = 31, test_days=395)\n",
    "rand_sm_pred.y_hat = rand_sm_pred.y_hat.astype(float)\n",
    "rand_sm_pred.y_test = rand_sm_pred.y_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_sm_pred_RMSE, rand_sm_pred_MAE, rand_sm_corr = calculate_statistics(rand_sm_pred.y_test.values, rand_sm_pred.y_hat.values)\n",
    "print(\"Root Mean Squared Error:\", rand_sm_pred_RMSE)\n",
    "print(\"Mean Absolute Error:\", rand_sm_pred_MAE)\n",
    "print(\"Correlation:\", rand_sm_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of the predicted prices versus the real prices\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Smart Meter -\" +smart_meters[ep]+\"- Energy Consumption 2013\")\n",
    "plt.plot(rand_sm_pred.y_test.values, color = 'green', label = 'Real kWH')\n",
    "plt.plot(rand_sm_pred.y_hat.values, color = 'red', label = 'Predicted kWH')\n",
    "ax.set_ylabel(\"kWh\")\n",
    "ax.set_xlabel(\"Time (half-hours)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 800  # Set Frequency To 2500 Hertz\n",
    "duration = 5000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
